{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module pipeline\n",
    "\n",
    "> Here we have the Nodes wrapping around our core functions, which can be added to a Nipype workflow to process your input images. These definitions here are our custom functions and Nipype Nodes knotted together, which creates a working pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#export\n",
    "import os, sys\n",
    "from shutil import which\n",
    "\n",
    "import pipetography.core as ppt\n",
    "\n",
    "from nipype import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.pipeline import Node, MapNode, Workflow\n",
    "from nipype.interfaces.mrtrix3.utils import BrainMask, DWIExtract, MRMath\n",
    "from nipype.interfaces.mrtrix3.preprocess import MRDeGibbs\n",
    "from nipype.interfaces import ants\n",
    "from nipype.interfaces import fsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `pipeline` class that puts everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class pipeline:\n",
    "    \"\"\"\n",
    "    A class containing functionalities and inputs to the image processing pipeline\n",
    "    Input: \n",
    "        BIDS_dir (str): Valid BIDS directory with DWI modality\n",
    "    Attributes:\n",
    "        data_dir (str)\n",
    "        sub_list (List)\n",
    "        layout (PyBIDS Layout)\n",
    "        bfiles_fsl (tuple)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, BIDS_dir=\"data\"):\n",
    "        # variables\n",
    "        self.data_dir = BIDS_dir\n",
    "        self.sub_list, self.layout = ppt.get_subs(self.data_dir)\n",
    "        self.dwi_file = os.path.join(\n",
    "            \"sub-{subject_id}\", \"ses-*\", \"dwi\", \"sub-{subject_id}_ses-*_dwi.nii.gz\",\n",
    "        )\n",
    "        self.b_files = os.path.join(\n",
    "            \"sub-{subject_id}\", \"ses-1\", \"dwi\", \"sub-{subject_id}_ses-1_dwi.bv*\"\n",
    "        )\n",
    "        self.sub_template = {\"dwi\": self.dwi_file, \"b_files\": self.b_files}\n",
    "        # node for reading inputs\n",
    "        self.sub_source = Node(IdentityInterface(fields=[\"subject_id\"]), name=\"data_source\")\n",
    "        self.sub_source.iterables = [(\"subject_id\", self.sub_list)]\n",
    "        # node for selecting images and bfiles\n",
    "        self.select_files = Node(\n",
    "            SelectFiles(self.sub_template, base_directory=self.data_dir), name=\"select_files\",\n",
    "        )\n",
    "        self.bfiles_input = Node(\n",
    "            Function(\n",
    "                input_names=[\"in_List\"], output_names=[\"out_path\"], function=ppt.get_bfiles_tuple,\n",
    "            ),\n",
    "            name=\"select_bfiles\",\n",
    "        )\n",
    "        # preprocessing nodes:\n",
    "        self.denoise = MapNode(ppt.dwidenoise(), name=\"denoise\", iterfield=\"in_file\")\n",
    "        self.ringing = MapNode(MRDeGibbs(), name=\"ringing_removal\", iterfield=\"in_file\")\n",
    "        self.ants_bfc = MapNode(\n",
    "            ppt.N4BiasFieldCorrection(), name=\"ants_bias_correct\", iterfield=\"in_file\",\n",
    "        )\n",
    "        self.mrt_preproc = MapNode(ppt.dwipreproc(), name=\"mrtrix3_preproc\", iterfield=\"in_file\")\n",
    "        # atlases:\n",
    "        self.atlas_dir = None\n",
    "        self.atlas_names = None\n",
    "        self.atlas_source = None\n",
    "        self.select_atlas = None\n",
    "        # b0 volume brain and mask extraction:\n",
    "        self.b0extract = MapNode(DWIExtract(), name=\"dwiextract\", iterfield=\"in_file\")\n",
    "        self.b0mean = MapNode(MRMath(), name=\"mrmath\", iterfield=\"in_file\")\n",
    "        self.fsl_bet = MapNode(fsl.BET(), name=\"brain_extraction\", iterfield=\"in_file\")\n",
    "        # ants coregistration:\n",
    "        self.linear_coreg = MapNode(\n",
    "            ants.Registration(), name=\"linear_registration\", iterfield=\"fixed_image\",\n",
    "        )\n",
    "        self.nonlinear_coreg = MapNode(\n",
    "            ants.Registration(), name=\"nonlinear_registration\", iterfield=\"fixed_image\",\n",
    "        )\n",
    "        # data sink:\n",
    "        self.datasink = Node(DataSink(), name=\"datasink\")\n",
    "        # workflow for nipype\n",
    "        self.workflow = None\n",
    "        #\n",
    "        \n",
    "    def check_environment(self):\n",
    "        \"\"\"\n",
    "        Check your computing environment for FSL environment variables `FSLOUTPUTTYPE` and `FSLDIR`\n",
    "        Check if ANTs PATH is included in your environment\n",
    "        Check if mrtrix3 is in your PATH\n",
    "        \"\"\"\n",
    "        assert \"FSLOUTPUTTYPE\" in os.environ\n",
    "        assert \"FSLDIR\" in os.environ\n",
    "        if \"FSLOUTPUTTYPE\" in os.environ:\n",
    "            print(\"FSLOUTPUTTYPE is valid\")\n",
    "        else:\n",
    "            sys.exit(\"FSLOUTPUTTYPE is not defined, make sure FSL is configured!\")\n",
    "\n",
    "        if \"FSLDIR\" in os.environ:\n",
    "            print(\"FSLDIR is valid\")\n",
    "        else:\n",
    "            sys.exit(\"FSLOUTPUTTYPE is not defined, make sure FSL is configured!\")\n",
    "        \n",
    "        #ANTS:\n",
    "        assert \"ANTSPATH\" in os.environ\n",
    "        print(\"ANTS is valid\")\n",
    "        #mrtrix:\n",
    "        assert which('mrview') is not None\n",
    "        print(\"mrtrix3 is valid\")\n",
    "        return None\n",
    "        #\n",
    "        \n",
    "    def set_datasink(self):\n",
    "        \"\"\"\n",
    "        Set directory where output files will be placed\n",
    "        \"\"\"\n",
    "        output_dir = str(input('Please indicate an output directory: '))\n",
    "        self.datasink.inputs.base_directory = output_dir\n",
    "\n",
    "    def denoise_inputs(\n",
    "        self,\n",
    "        out_file=\"denoised.nii.gz\",\n",
    "        noise_file=\"noise_map.nii.gz\",\n",
    "        force=False,\n",
    "        quiet=False,\n",
    "        nthreads=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Set inputs to denoise node\n",
    "        \"\"\"\n",
    "        self.denoise.inputs.out_file = out_file\n",
    "        self.denoise.inputs.noise = noise_file\n",
    "        if force is True:\n",
    "            self.denoise.inputs.force = \"-force\"\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if quiet is True:\n",
    "            self.denoise.inputs.quiet = \"-quiet\"\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if nthreads is None:\n",
    "            pass\n",
    "        elif type(nthreads) == int:\n",
    "            self.denoise.inputs.nthreads = nthreads\n",
    "        else:\n",
    "            sys.exit(\"denoise nthreads input has to be an integer\")\n",
    "\n",
    "    def DeGibbs_inputs(self, out_file=\"ringing_removed.nii.gz\"):\n",
    "        \"\"\"\n",
    "        Set inputs to ringing removal node\n",
    "        \"\"\"\n",
    "        self.ringing.inputs.out_file = out_file\n",
    "\n",
    "    def ants_bfc_inputs(self, out_file=\"biasfieldcorrected.nii.gz\", dims=4):\n",
    "        \"\"\"\n",
    "        Set inputs to ANTs bias field correction node, currently incomplete\n",
    "        \"\"\"\n",
    "        self.ants_bfc.inputs.out_file = out_file\n",
    "        self.ants_bfc.inputs.dims = dims\n",
    "\n",
    "    def mrt_preproc_inputs(\n",
    "        self, rpe_options, pe_dir, eddy_options, nthreads, out_file=\"preproc.nii.gz\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Set inputs to mrtrix3's dwipreproc.\n",
    "        Arguments:\n",
    "            out_file: name of output file\n",
    "            rpe_options (str): specify phase encoding design -rpe_+ 'none/pair/all/header'\n",
    "            pe_dir (str): phase encoding direction(i,j,k)/(0,1,2)/(RL,PA,IS)\n",
    "            eddy_options (str): '\"--slm=linear \"' aditional commandline options to eddy command, with at least 1  space\n",
    "        \"\"\"\n",
    "        self.mrt_preproc.inputs.out_file = out_file\n",
    "        self.mrt_preproc.inputs.rpe_options = rpe_options  # -rpe_none\n",
    "        self.mrt_preproc.inputs.pe_dir = pe_dir\n",
    "        self.mrt_preproc.inputs.eddy_options = eddy_options\n",
    "        if nthreads is None:\n",
    "            pass\n",
    "        elif type(nthreads) == int:\n",
    "            self.mrt_preproc.inputs.nthreads = nthreads\n",
    "        else:\n",
    "            sys.exit(\"denoise nthreads input has to be an integer\")\n",
    "\n",
    "    def atlas_inputs(self, atlas_dir, atlas_names):\n",
    "        \"\"\"\n",
    "        Input where to load atlases for ROIs and co-registration\n",
    "        \"\"\"\n",
    "        self.atlas_dir = atlas_dir\n",
    "        self.atlas_names = atlas_names\n",
    "        atlas_template = {\"atlas\": atlas_dir + \"{file_name}\"}\n",
    "        self.atlas_source = Node(IdentityInterface(fields=[\"atlas_name\"]), name=\"atlas_source\")\n",
    "        self.atlas_source.iterables = [(\"atlas_name\"), self.atlas_names]\n",
    "        self.select_atlas = Node(SelectFiles(atlas_template), name=\"select_atlases\")\n",
    "        self.select_atlas.base_directory = self.atlas_dir\n",
    "\n",
    "    def b0extract_inputs(self, out_file=\"dwi_b0.nii.gz\", bzero=True):\n",
    "        self.b0extract.inputs.out_file = out_file\n",
    "        self.b0extract.inputs.bzero = bzero\n",
    "\n",
    "    def b0mean_inputs(self, out_file=\"dwi_b0_mean.nii.gz\", axis=3):\n",
    "        self.b0mean.inputs.operation = \"mean\"\n",
    "        self.b0mean.inputs.axis = axis\n",
    "        self.b0mean.inputs.out_file = out_file\n",
    "\n",
    "    def bet_inputs(\n",
    "        self, robust=True, mask=True, frac=0.25, out_file=\"dwi_brain.nii.gz\"\n",
    "    ):\n",
    "        if robust is True:\n",
    "            self.fsl_bet.inputs.robust = robust\n",
    "        else:\n",
    "            self.fsl_bet.inputs.reduce_bias = False\n",
    "\n",
    "        self.fsl_bet.inputs.mask = mask\n",
    "        self.fsl_bet.inputs.frac = 0.25\n",
    "        self.fsl_bet.inputs.out_file = out_file\n",
    "\n",
    "    def linear_coreg_inputs(\n",
    "        self,\n",
    "        dims=3,\n",
    "        prefix=\"atlas_in_dwi_affine\",\n",
    "        collapse=True,\n",
    "        transform=[\"Affine\"],\n",
    "        parameters=[(0.1,)],\n",
    "        metric=[\"MI\"],\n",
    "        weight=[1],\n",
    "        radius_bins=[64],\n",
    "        num_iter=[[500, 200, 200, 100]],\n",
    "        threshold=[1e-06],\n",
    "        window_size=[10],\n",
    "        sigmas=[[4, 2, 1, 0]],\n",
    "        units=[\"vox\"],\n",
    "        shrink=[[8, 4, 2, 1]],\n",
    "        histogram=True,\n",
    "        output=\"atlas_in_dwi_affine.nii.gz\",\n",
    "    ):\n",
    "        self.linear_coreg.inputs.dimension = dims\n",
    "        self.linear_coreg.inputs.output_transform_prefix = prefix\n",
    "        self.linear_coreg.inputs.collapse_output_transforms = collapse\n",
    "        self.linear_coreg.inputs.transforms = transform\n",
    "        self.linear_coreg.inputs.transform_parameters = parameters\n",
    "        self.linear_coreg.inputs.metric = metric\n",
    "        self.linear_coreg.inputs.metric_weight = weight  # default, value ignored by ANTS\n",
    "        self.linear_coreg.inputs.radius_or_number_of_bins = radius_bins\n",
    "        # -convergence\n",
    "        self.linear_coreg.inputs.number_of_iterations = num_iter\n",
    "        self.linear_coreg.inputs.convergence_threshold = threshold\n",
    "        self.linear_coreg.inputs.convergence_window_size = window_size\n",
    "        # -s\n",
    "        self.linear_coreg.inputs.smoothing_sigmas = sigmas\n",
    "        self.linear_coreg.inputs.sigma_units = units\n",
    "        # -f\n",
    "        self.linear_coreg.inputs.shrink_factors = shrink\n",
    "        self.linear_coreg.inputs.use_histogram_matching = histogram  # -u flag\n",
    "        self.linear_coreg.inputs.output_warped_image = output\n",
    "    \n",
    "    def nonlinear_coreg_inputs(\n",
    "        self,\n",
    "        dims=3,\n",
    "        prefix=\"atlas_in_dwi_syn\",\n",
    "        collapse=True,\n",
    "        transform=['SyN'],\n",
    "        parameters=[(0.1,)],\n",
    "        metric=[\"MI\"],\n",
    "        weight=[1],\n",
    "        radius_bins=[64],\n",
    "        num_iter=[[500, 200, 200, 100]],\n",
    "        threshold=[1e-06],\n",
    "        window_size=[10],\n",
    "        sigmas=[[4, 2, 1, 0]],\n",
    "        units=[\"vox\"],\n",
    "        shrink=[[8, 4, 2, 1]],\n",
    "        histogram=True,\n",
    "        output=\"atlas_in_dwi_syn.nii.gz\",\n",
    "    ):\n",
    "        self.nonlinear_coreg.inputs.dimension = dims\n",
    "        self.nonlinear_coreg.inputs.output_transform_prefix = prefix\n",
    "        self.nonlinear_coreg.inputs.collapse_output_transforms = collapse\n",
    "        self.nonlinear_coreg.inputs.transforms = transform\n",
    "        self.nonlinear_coreg.inputs.transform_parameters = parameters\n",
    "        self.nonlinear_coreg.inputs.metric = metric\n",
    "        self.nonlinear_coreg.inputs.metric_weight = weight  # default, value ignored by ANTS\n",
    "        self.nonlinear_coreg.inputs.radius_or_number_of_bins = radius_bins\n",
    "        # -convergence\n",
    "        self.nonlinear_coreg.inputs.number_of_iterations = num_iter\n",
    "        self.nonlinear_coreg.inputs.convergence_threshold = threshold\n",
    "        self.nonlinear_coreg.inputs.convergence_window_size = window_size\n",
    "        # -s\n",
    "        self.nonlinear_coreg.inputs.smoothing_sigmas = sigmas\n",
    "        self.nonlinear_coreg.inputs.sigma_units = units\n",
    "        # -f\n",
    "        self.nonlinear_coreg.inputs.shrink_factors = shrink\n",
    "        self.nonlinear_coreg.inputs.use_histogram_matching = histogram  # -u flag\n",
    "        self.nonlinear_coreg.inputs.output_warped_image = output\n",
    "\n",
    "    def connect_nodes(self, wf_name=\"pipetography\"):\n",
    "        # a workflow that will be filled in:\n",
    "        self.workflow = Workflow(name=wf_name, base_dir=self.data_dir + \"/derivatives\",)\n",
    "        # folder -> select files\n",
    "        self.workflow.connect(\n",
    "            self.sub_source, \"subject_id\", self.select_files, \"subject_id\",\n",
    "        )\n",
    "        # select files -> obtain bvec/bval path as tuple\n",
    "        self.workflow.connect(\n",
    "            self.select_files, \"b_files\", self.bfiles_input, \"in_List\",\n",
    "        )\n",
    "        # selected dwi -> denoise\n",
    "        self.workflow.connect(\n",
    "            self.select_files, \"dwi\", self.denoise, \"in_file\",\n",
    "        )\n",
    "        # denoised output -> datasink\n",
    "        self.workflow.connect(\n",
    "            self.denoise, \"out_file\", self.datasink, \"preproc.@denoised\",\n",
    "        )\n",
    "        # denoised output -> ringing removal\n",
    "        self.workflow.connect(\n",
    "            self.denoise, \"out_file\", self.ringing, \"in_file\",\n",
    "        )\n",
    "        # ringing removal -> datasink\n",
    "        self.workflow.connect(\n",
    "            self.ringing, \"out_file\", self.datasink, \"preproc.@ringing_removed\",\n",
    "        )\n",
    "        # ringing removal -> bias field correction\n",
    "        self.workflow.connect(\n",
    "            self.ringing, \"out_file\", self.ants_bfc, \"in_file\",\n",
    "        )\n",
    "        # bias field corrected -> datasink\n",
    "        self.workflow.connect(\n",
    "            self.ants_bfc, \"out_file\", self.datasink, \"preproc.@biasCorrected\",\n",
    "        )\n",
    "        # bias field corrected -> eddy correction\n",
    "        self.workflow.connect(\n",
    "            self.ants_bfc, \"out_file\", self.mrt_preproc, \"in_file\",\n",
    "        )\n",
    "        # grad_fsl for eddy correction:\n",
    "        self.workflow.connect(\n",
    "            self.bfiles_input, \"out_path\", self.mrt_preproc, \"grad_fsl\",\n",
    "        )\n",
    "        # preproc --> data sink\n",
    "        self.workflow.connect(\n",
    "            self.mrt_preproc, \"out_file\", self.datasink, \"preproc.@preproced\",\n",
    "        )\n",
    "        # b0 extractions:\n",
    "        self.workflow.connect(\n",
    "            self.mrt_preproc, \"out_file\", self.b0extract, \"in_file\",\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.bfiles_input, \"out_path\", self.b0extract, \"grad_fsl\",\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.b0extract, \"out_file\", self.b0mean, \"in_file\",\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.b0mean, \"out_file\", self.fsl_bet, \"in_file\",\n",
    "        )\n",
    "        # extractions --> datasink:\n",
    "        self.workflow.connect(\n",
    "            self.b0extract, \"out_file\", self.datasink, \"extraction.@volume\",\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.b0mean, \"out_file\", self.datasink, \"extraction.@mean\",\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.fsl_bet, \"mask_file\", self.datasink, \"extraction.@BET_mask\",\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.fsl_bet, \"out_file\", self.datasink, \"extraction.@BET_image\",\n",
    "        )\n",
    "        # coregistration of atlases to DWI, select atlases as moving image\n",
    "        self.workflow.connect(\n",
    "            self.atlas_source, 'atlas_name', self.select_atlas, 'file_name'\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.select_atlas, 'atlas', self.linear_coreg, 'moving_image'\n",
    "        )\n",
    "        # use extracted brain as target brain for co-registration, no dwi noise\n",
    "        self.workflow.connect(\n",
    "            self.fsl_bet, 'out_file', self.linear_coreg, 'fixed_image'\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.fsl_bet, 'out_file', self.nonlinear_coreg, 'fixed_image'\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.linear_coreg, 'warped_image', self.nonlinear_coreg, 'moving_image'\n",
    "        )\n",
    "        # coreg --> datasink\n",
    "        self.workflow.connect(\n",
    "            self.linear_coreg, 'warped_image', self.datasink, 'coreg.@affine_atlas'\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.nonlinear_coreg, 'warped_image', self.datasink, 'coreg.@syn_atlas'\n",
    "        )\n",
    "        #\n",
    "        \n",
    "    def default_setup(self, phase_encoding_design = \"-rpe_none\", phase_encoding_dir = \"j-\"):\n",
    "        \"\"\"\n",
    "        Set up pipeline parameters with all default settings blindly\n",
    "        You want to use this for a quick test run. Then tweak parameters after examining all output images\n",
    "        Note that this assumes input options for eddy current correction as \"--slm=linear\" \n",
    "        Arguments:\n",
    "            phase_encoding_design (str): defaults to \"-rpe_none\", or no reverse phase encoding volume, eddy current and motion correction only, other options include \"rpe_pair, rpe_all, rpe_header\"\n",
    "            phase_encoding_dir (str): defaults to \"j-\", or anterior to posterior. (Options: i,j,k or RL, PA, IS)\n",
    "        \"\"\"\n",
    "        self.denoise_inputs(force = True, quiet = True)\n",
    "        self.DeGibbs_inputs()\n",
    "        self.ants_bfc_inputs()\n",
    "        self.mrt_preproc_inputs(\n",
    "            rpe_options=phase_encoding_design,\n",
    "            pe_dir=phase_encoding_dir,\n",
    "            eddy_options='\"--slm=linear --verbose\"',\n",
    "            nthreads=4,\n",
    "            )\n",
    "        self.b0extract_inputs()\n",
    "        self.b0mean_inputs()\n",
    "        self.bet_inputs()\n",
    "        self.atlas_inputs(atlas_dir=str(input('Please indicate directory with atlas volumes: ')), atlas_names=list(input('Please indicate list of selected atlas names: ')))\n",
    "        self.linear_coreg_inputs() #defaults\n",
    "        self.nonlinear_coreg_inputs() #defaults\n",
    "        self.connect_nodes(wf_name = 'default_workflow')\n",
    "        return print(self.__dict__)\n",
    "        \n",
    "    def draw_pipeline(self):\n",
    "        self.workflow.write_graph(graph2use='orig', dotfilename = 'pipetography.dot')\n",
    "        \n",
    "    def run_pipeline(self, parallel = True):\n",
    "        if parallel is True:\n",
    "            processes = int(input('Number of Processes: '))\n",
    "            self.workflow.run('MultiProc', plugin_args = {'n_procs': processes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating layout of data directory, might take a while if there are a lot of subjects\n"
     ]
    }
   ],
   "source": [
    "#example usage, create pipeline:\n",
    "preproc_dwi = pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if our environment is properly set-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FSLOUTPUTTYPE is valid\n",
      "FSLDIR is valid\n",
      "ANTS is valid\n",
      "mrtrix3 is valid\n"
     ]
    }
   ],
   "source": [
    "preproc_dwi.check_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please indicate an output directory:  'output'\n"
     ]
    }
   ],
   "source": [
    "# set output destination:\n",
    "preproc_dwi.set_datasink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at what's in the `pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_dir': 'data',\n",
       " 'sub_list': ['11048'],\n",
       " 'layout': BIDS Layout: ...ers/xxie/lab/pipetography/data | Subjects: 1 | Sessions: 1 | Runs: 0,\n",
       " 'dwi_file': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz',\n",
       " 'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*',\n",
       " 'sub_template': {'dwi': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz',\n",
       "  'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*'},\n",
       " 'sub_source': data_source,\n",
       " 'select_files': select_files,\n",
       " 'bfiles_input': select_bfiles,\n",
       " 'denoise': denoise,\n",
       " 'ringing': ringing_removal,\n",
       " 'ants_bfc': ants_bias_correct,\n",
       " 'mrt_preproc': mrtrix3_preproc,\n",
       " 'atlas_dir': None,\n",
       " 'atlas_names': None,\n",
       " 'atlas_source': None,\n",
       " 'select_atlas': None,\n",
       " 'b0extract': dwiextract,\n",
       " 'b0mean': mrmath,\n",
       " 'fsl_bet': brain_extraction,\n",
       " 'linear_coreg': linear_registration,\n",
       " 'nonlinear_coreg': nonlinear_registration,\n",
       " 'datasink': datasink,\n",
       " 'workflow': None}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_dwi.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set up preprocessing pipeline with default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please indicate directory with atlas volumes:  '/Users/xxie/lab/atlases'\n",
      "Please indicate list of selected atlas names:  ['BN_Atlas_246_2mm.nii','DK_atlas86_1mm.nii']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dir': 'data', 'sub_list': ['11048'], 'layout': BIDS Layout: ...ers/xxie/lab/pipetography/data | Subjects: 1 | Sessions: 1 | Runs: 0, 'dwi_file': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz', 'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*', 'sub_template': {'dwi': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz', 'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*'}, 'sub_source': default_workflow.data_source, 'select_files': default_workflow.select_files, 'bfiles_input': default_workflow.select_bfiles, 'denoise': default_workflow.denoise, 'ringing': default_workflow.ringing_removal, 'ants_bfc': default_workflow.ants_bias_correct, 'mrt_preproc': default_workflow.mrtrix3_preproc, 'atlas_dir': \"'/Users/xxie/lab/atlases'\", 'atlas_names': ['[', \"'\", 'B', 'N', '_', 'A', 't', 'l', 'a', 's', '_', '2', '4', '6', '_', '2', 'm', 'm', '.', 'n', 'i', 'i', \"'\", ',', \"'\", 'D', 'K', '_', 'a', 't', 'l', 'a', 's', '8', '6', '_', '1', 'm', 'm', '.', 'n', 'i', 'i', \"'\", ']'], 'atlas_source': default_workflow.atlas_source, 'select_atlas': default_workflow.select_atlases, 'b0extract': default_workflow.dwiextract, 'b0mean': default_workflow.mrmath, 'fsl_bet': default_workflow.brain_extraction, 'linear_coreg': default_workflow.linear_registration, 'nonlinear_coreg': default_workflow.nonlinear_registration, 'datasink': default_workflow.datasink, 'workflow': default_workflow}\n"
     ]
    }
   ],
   "source": [
    "preproc_dwi.default_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR we can fill this in one by one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's tell the pipeline where we have atlas volumes and which ones to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_dwi.atlas_inputs(atlas_dir = '/Users/xxie/lab/atlases', atlas_names = ['BN_Atlas_246_2mm.nii','DK_atlas86_1mm.nii'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we give inputs to the `denoise` Node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_dwi.denoise_inputs(force = True, quiet = True)\n",
    "# we kept everything else default, like output names and number of threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gibbs ringing removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_dwi.DeGibbs_inputs() # keep it default\n",
    "print('Output file name is ' + preproc_dwi.ringing.inputs.out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANTs Bias Field Correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_dwi.ants_bfc_inputs() # keep it default:\n",
    "preproc_dwi.ants_bfc.inputs.print_traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`in_file` is undefined because we will feed it this information once we connect our individual functions.\n",
    "\n",
    "Next let's set up eddy current/motion correction, we need to tell the pipeline the phase encoding settings and inputs to eddy algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_dwi.mrt_preproc_inputs(\n",
    "    rpe_options=\"-rpe_none\",\n",
    "    pe_dir=\"j-\",\n",
    "    eddy_options='\"--slm=linear --verbose\"',\n",
    "    nthreads=4,\n",
    ")\n",
    "preproc_dwi.mrt_preproc.inputs.print_traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grad_fsl` and `in_file` will be input via connected workflow later\n",
    "\n",
    "Next, we set-up brain extraction from B0 volumes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract b0 volumes:\n",
    "preproc_dwi.b0extract_inputs() #default\n",
    "# Create average B0 volume:\n",
    "preproc_dwi.b0mean_inputs() #default\n",
    "# Extract brain from B0 average volume:\n",
    "preproc_dwi.bet_inputs() #defaults again, using FSL's BET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANTs registration set up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_dwi.linear_coreg_inputs() #defaults\n",
    "preproc_dwi.nonlinear_coreg_inputs() #defaults\n",
    "preproc_dwi.nonlinear_coreg.inputs.print_traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the default settings may not be optimal for your dataset, run the processing for a test image and see the intermediate results and then tweak the available inputs to improve the output image quality.\n",
    "\n",
    "Now that our pre-processing Nodes are properly setup, we can connect and create a workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_dwi.connect_nodes(wf_name = 'pipetography_workflow')\n",
    "preproc_dwi.draw_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the final workflow we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('data/derivatives/test_run/pipetography_detailed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracts",
   "language": "python",
   "name": "tracts"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
