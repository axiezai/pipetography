{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module pipeline\n",
    "\n",
    "> Here we have the Nodes wrapping around our core functions, which can be added to a Nipype workflow to process your input images. These definitions here are our custom functions and Nipype Nodes knotted together, which creates a working pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#export\n",
    "import os, sys\n",
    "from shutil import which\n",
    "\n",
    "import pipetography.core as ppt\n",
    "\n",
    "from nipype import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.pipeline import Node, MapNode, Workflow\n",
    "from nipype.interfaces.mrtrix3.utils import BrainMask, MRConvert, DWIExtract, MRMath\n",
    "from nipype.interfaces.mrtrix3.preprocess import MRDeGibbs\n",
    "from nipype.interfaces import ants\n",
    "from nipype.interfaces import fsl\n",
    "from nipype.interfaces.freesurfer.preprocess import ReconAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `pipeline` class that puts everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class pipeline:\n",
    "    \"\"\"\n",
    "    A class containing functionalities and inputs to the image processing pipeline\n",
    "    Input: \n",
    "        BIDS_dir (str): Valid BIDS directory with DWI modality\n",
    "    Attributes:\n",
    "        data_dir (str)\n",
    "        sub_list (List)\n",
    "        layout (PyBIDS Layout)\n",
    "        bfiles_fsl (tuple)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, BIDS_dir=\"data\"):\n",
    "        # variables\n",
    "        self.data_dir = BIDS_dir\n",
    "        self.sub_list, self.layout = ppt.get_subs(self.data_dir)\n",
    "        self.dwi_file = os.path.join(\n",
    "            \"sub-{subject_id}\", \"ses-*\", \"dwi\", \"sub-{subject_id}_ses-*_dwi.nii.gz\",\n",
    "        )\n",
    "        self.b_files = os.path.join(\n",
    "            \"sub-{subject_id}\", \"ses-1\", \"dwi\", \"sub-{subject_id}_ses-1_dwi.bv*\"\n",
    "        )\n",
    "        self.sub_template = {\"dwi\": self.dwi_file, \"b_files\": self.b_files}\n",
    "        \n",
    "        # node for reading inputs\n",
    "        self.sub_source = Node(IdentityInterface(fields=[\"subject_id\"]), name=\"data_source\")\n",
    "        self.sub_source.iterables = [(\"subject_id\", self.sub_list)]\n",
    "        \n",
    "        # node for selecting images and bfiles\n",
    "        self.select_files = Node(\n",
    "            SelectFiles(self.sub_template, base_directory=self.data_dir), name=\"select_files\",\n",
    "        )\n",
    "        self.bfiles_input = Node(\n",
    "            Function(\n",
    "                input_names=[\"in_List\"], output_names=[\"out_path\"], function=ppt.get_bfiles_tuple,\n",
    "            ),\n",
    "            name=\"select_bfiles\",\n",
    "        )\n",
    "        \n",
    "        # ACPC HCP MNI152 alignment nodes:\n",
    "        # first define template location in FSL:\n",
    "        self.MNI_template = os.path.expandvars('$FSLDIR/data/standard/MNI152_T1_1mm.nii.gz')\n",
    "        self.reduceFOV = MapNode(fsl.utils.RobustFOV(), name=\"reduce_FOV\", iterfield=\"in_file\")\n",
    "        self.xfminverse = MapNode(fsl.utils.ConvertXFM(), name=\"transform_inverse\", iterfield=\"in_file\")\n",
    "        self.flirt = MapNode(fsl.preprocess.FLIRT(), name=\"FLIRT\", iterfield=\"in_file\")\n",
    "        self.concatxfm = MapNode(fsl.utils.ConvertXFM(), name=\"concat_transform\", iterfield=[\"in_file\", \"in_file2\"])\n",
    "        self.alignxfm = MapNode(ppt.fslaff2rigid(), name='aff2rigid', iterfield=\"in_file\")\n",
    "        self.ACPC_warp = MapNode(fsl.preprocess.ApplyWarp(), name='apply_warp', iterfield=[\"in_file\",\"premat\"])\n",
    "        \n",
    "        # FreeSurfer recon-all mainly for WM segmentation\n",
    "        # we are greedy so we just let it segment and produce everything\n",
    "        self.reconall = MapNode(ReconAll(), name='FSrecon', iterfield=\"T1_files\")\n",
    "        \n",
    "        # Preparation nodes (mask, check gradient, convert):\n",
    "        self.mrconvert = MapNode(ppt.Convert(), name='mrtrix_image', iterfield=\"in_file\")\n",
    "        self.createMask = MapNode(BrainMask(), name='dwi2mask', iterfield='in_file')\n",
    "        self.GradCheck = MapNode(ppt.GradCheck(), name='dwigradcheck', iterfield='in_file')\n",
    "        self.NewGradMR = MapNode(ppt.Convert(), name='mrconvert', iterfield = \"in_file\")\n",
    "        \n",
    "        # preprocessing nodes:\n",
    "        self.denoise = MapNode(ppt.dwidenoise(), name=\"denoise\", iterfield=\"in_file\")\n",
    "        self.ringing = MapNode(MRDeGibbs(), name=\"ringing_removal\", iterfield=\"in_file\")\n",
    "        self.ants_bfc = MapNode(\n",
    "            ppt.N4BiasFieldCorrection(), name=\"ants_bias_correct\", iterfield=\"in_file\",\n",
    "        )\n",
    "        self.mrt_preproc = MapNode(ppt.dwipreproc(), name=\"mrtrix3_preproc\", iterfield=\"in_file\")\n",
    "        # atlases:\n",
    "        self.atlas_dir = None\n",
    "        self.atlas_names = None\n",
    "        self.atlas_source = None\n",
    "        self.select_atlas = None\n",
    "        # b0 volume brain and mask extraction:\n",
    "        self.b0extract = MapNode(DWIExtract(), name=\"dwiextract\", iterfield=\"in_file\")\n",
    "        self.b0mean = MapNode(MRMath(), name=\"mrmath\", iterfield=\"in_file\")\n",
    "        self.fsl_bet = MapNode(fsl.BET(), name=\"brain_extraction\", iterfield=\"in_file\")\n",
    "        # ants coregistration:\n",
    "        self.linear_coreg = MapNode(\n",
    "            ants.Registration(), name=\"linear_registration\", iterfield=\"fixed_image\",\n",
    "        )\n",
    "        self.nonlinear_coreg = MapNode(\n",
    "            ants.Registration(), name=\"nonlinear_registration\", iterfield=\"fixed_image\",\n",
    "        )\n",
    "        # data sink:\n",
    "        self.datasink = Node(DataSink(), name=\"datasink\")\n",
    "        # workflow for nipype\n",
    "        self.workflow = None\n",
    "    \n",
    "        \n",
    "    def check_environment(self):\n",
    "        \"\"\"\n",
    "        Check your computing environment for FSL environment variables `FSLOUTPUTTYPE` and `FSLDIR`\n",
    "        Check if ANTs PATH is included in your environment\n",
    "        Check if mrtrix3 is in your PATH\n",
    "        \"\"\"\n",
    "        assert \"FSLOUTPUTTYPE\" in os.environ\n",
    "        assert \"FSLDIR\" in os.environ\n",
    "        if \"FSLOUTPUTTYPE\" in os.environ:\n",
    "            print(\"FSLOUTPUTTYPE is valid\")\n",
    "        else:\n",
    "            sys.exit(\"FSLOUTPUTTYPE is not defined, make sure FSL is configured!\")\n",
    "\n",
    "        if \"FSLDIR\" in os.environ:\n",
    "            print(\"FSLDIR is valid\")\n",
    "        else:\n",
    "            sys.exit(\"FSLOUTPUTTYPE is not defined, make sure FSL is configured!\")\n",
    "        \n",
    "        #ANTS:\n",
    "        assert \"ANTSPATH\" in os.environ\n",
    "        print(\"ANTS is valid\")\n",
    "        #mrtrix:\n",
    "        assert which('mrview') is not None\n",
    "        print(\"mrtrix3 is valid\")\n",
    "        return None\n",
    "    \n",
    "        \n",
    "    def set_datasink(self):\n",
    "        \"\"\"\n",
    "        Set directory where output files will be placed\n",
    "        \"\"\"\n",
    "        output_dir = str(input('Please indicate an output directory: '))\n",
    "        self.datasink.inputs.base_directory = output_dir\n",
    "    \n",
    "    \n",
    "    def reduceFOV_inputs(\n",
    "        self,\n",
    "        xfm_mat=\"roi2full.mat\",\n",
    "        out_vol=\"robustfov.nii.gz\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inputs to FSL's robustfov command: robustfov -i [input] -m [matrix name] -r [volume name]\n",
    "        \"\"\"\n",
    "        self.reduceFOV.inputs.out_transform = xfm_mat\n",
    "        self.reduceFOV.inputs.out_roi = out_vol\n",
    "    \n",
    "    \n",
    "    def flirt_inputs(\n",
    "        self,\n",
    "        template=self.MNI_template,\n",
    "        method='spline',\n",
    "        mat_file='roi2std.mat',\n",
    "        out_file='acpc_mni.nii.gz'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inputs to FSL's FLIRT:\n",
    "        -Iterable input is robustfov.nii.gz (robustFOV's output)\n",
    "        \"\"\"\n",
    "        self.FLIRT.inputs.reference = template\n",
    "        self.FLIRT.inputs.interp = method\n",
    "        self.FLIRT.inputs.out_matrix_file = mat_file\n",
    "        self.FLIRT.inputs.out_file = out_file\n",
    "    \n",
    "    \n",
    "    def xfminverse_inputs(\n",
    "        self,\n",
    "        inverse=True,\n",
    "        out_file='full2roi.mat'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inputs to FSL's convert_xfm command: convert_xfm -omat [filename] -inverse [input]\n",
    "        \"\"\"\n",
    "        self.xfminverse.inputs.out_file = out_file\n",
    "        self.xfminverse.inputs.invert_xfm = inverse\n",
    "    \n",
    "    \n",
    "    def concatxfm_inputs(\n",
    "        self,\n",
    "        concat = True,\n",
    "        omat = 'full2std.mat'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inputs for transformation matrix concatenation node\n",
    "        The matrices being concatenated are 1) flirt's output mat file  (in_file2) and 2) inverse mat file from the first convert_xfm (in_file)\n",
    "        \"\"\"\n",
    "        self.concatxfm.inputs.concat_xfm=True\n",
    "        self.concatxfm.inputs.out_file=omat\n",
    "        \n",
    "    \n",
    "    def aff2rigid_inputs(\n",
    "        self,\n",
    "        out_file='outputmatrix'\n",
    "    ):\n",
    "        self.alignxfm.inputs.out_file=out_file\n",
    "    \n",
    "    \n",
    "    def acpcwarp_inputs(\n",
    "        self,\n",
    "        out_file='acpc_t1.nii.gz',\n",
    "        rel_warp = True,\n",
    "        method = 'spline',\n",
    "        template = self.MNI_template,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inputs for FSL's `applywarp`\n",
    "        We want spline interpolation, relative warp field, premat = aff2rigid mat output.\n",
    "        \"\"\"\n",
    "        self.ACPC_warp.inputs.out_file = out_file\n",
    "        self.ACPC_warp.inputs.relwarp = rel_warp\n",
    "        self.ACPC_warp.inputs.interp = method\n",
    "        self.ACPC_warp.inputs.ref_file = template\n",
    "        \n",
    "    \n",
    "    # Freesurfer recon-all\n",
    "    def recon_inputs(\n",
    "        self,\n",
    "        hipp = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        We will multiproc the entire workflow, so parallel here is not recommended.\n",
    "        Only recommend parallel for single subject runs or group level runs.\n",
    "        \"\"\"\n",
    "        self.reconall.inputs.directive='all' # we always want recon-all -all\n",
    "        self.reconall.inputs.subjects_dir = self.BIDS_dir+'/derivatives/freesurfer'\n",
    "        self.reconall.inputs.hippocampal_subfields_T1 = True # we want this for compeleteness of data\n",
    "        #self.reconall.inputs.subject_id\n",
    "        \n",
    "    \n",
    "    # Convert to mrtrix3 file format:\n",
    "    def mrconvert_inputs(\n",
    "        self,\n",
    "        out_file = 'raw_dwi.mif',\n",
    "        export_mrtrix3_grad = True,\n",
    "        out_bfile = 'raw_dwi.b',\n",
    "        force = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Convert a DWI to mrtrix3's image format and gradient files\n",
    "        Workflow connected inputs not listed here:\n",
    "            - grad_fsl - gradient files in fsl format\n",
    "            - in_file - raw dwi that you want to convert to mrtrix3 format\n",
    "        \"\"\"\n",
    "        self.mrconvert.inputs.out_file = out_file\n",
    "        self.mrconvert.inputs.export_grad = export_mrtrix3_grad\n",
    "        self.mrconvert.inputs.out_bfile = out_bfile\n",
    "        self.mrconvert.inputs.force = force\n",
    "    \n",
    "    \n",
    "    # DWI Preprocessing mask creation:\n",
    "    def createMask_inputs(\n",
    "        self,\n",
    "        out_file = 'b0_brain_mask.mif'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create brain mask from B0 DWI volumes for preprocessing tasks.\n",
    "        in_file will be connected in workflow\n",
    "        \"\"\"\n",
    "        self.createMask.inputs.out_file = out_file\n",
    "        \n",
    "    \n",
    "    # gradient check and create files with corrected gradient:\n",
    "    def GradCheck_inputs(\n",
    "        self,\n",
    "        out_bfile = 'corrected.b',\n",
    "        export_mrtrix3_grad = True,\n",
    "        force = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Set inputs to dwigradcheck\n",
    "        Workflow inputs:\n",
    "            in_file = input from mrconvert Node \n",
    "            mask_file = input from createMask Node\n",
    "            grad_file = input from mrconvert Node\n",
    "        \"\"\"\n",
    "        self.GradCheck.inputs.export_grad = export_mrtrix3_grad\n",
    "        self.GradCheck.inputs.out_bfile = out_bfile\n",
    "        self.GradCheck.inputs.force = force\n",
    "    \n",
    "    \n",
    "    # Create new dwi image with corrected gradients:\n",
    "    def NewGradMR_inputs(\n",
    "        self,\n",
    "        out_file = 'cdwi.mif'\n",
    "        force = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inputs for creating gradient corrected MR\n",
    "        Outputs a correced dwi file\n",
    "        Workflow connected inputs:\n",
    "            in_file - output from mrconvert Node\n",
    "            grad_file - output from GradCheck Node (out_bfile)\n",
    "        \"\"\"\n",
    "        self.NewGradMR.inputs.out_file = out_file\n",
    "        self.NewGradMR.inputs.force = force\n",
    "        \n",
    "    \n",
    "    # MPPCA Denoise with dwidenoise from mrtrix3\n",
    "    def denoise_inputs(\n",
    "        self,\n",
    "        out_file=\"denoised.nii.gz\",\n",
    "        noise_file=\"noise_map.nii.gz\",\n",
    "        force=True,\n",
    "        quiet=False,\n",
    "        nthreads=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Set inputs to denoise node\n",
    "        \"\"\"\n",
    "        self.denoise.inputs.out_file = out_file\n",
    "        self.denoise.inputs.noise = noise_file\n",
    "        self.denoise.inputs.force = force\n",
    "\n",
    "        if quiet is True:\n",
    "            self.denoise.inputs.quiet = \"-quiet\"\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if nthreads is None:\n",
    "            pass\n",
    "        elif type(nthreads) == int:\n",
    "            self.denoise.inputs.nthreads = nthreads\n",
    "        else:\n",
    "            sys.exit(\"denoise nthreads input has to be an integer\")\n",
    "\n",
    "            \n",
    "    # Gibbs ringing artifact removal\n",
    "    def DeGibbs_inputs(self, out_file=\"ringing_removed.nii.gz\"):\n",
    "        \"\"\"\n",
    "        Set inputs to ringing removal node\n",
    "        \"\"\"\n",
    "        self.ringing.inputs.out_file = out_file\n",
    "\n",
    "        \n",
    "        \n",
    "    def ants_bfc_inputs(self, out_file=\"biasfieldcorrected.nii.gz\", dims=4):\n",
    "        \"\"\"\n",
    "        Set inputs to ANTs bias field correction node, currently incomplete\n",
    "        \"\"\"\n",
    "        self.ants_bfc.inputs.out_file = out_file\n",
    "        self.ants_bfc.inputs.dims = dims\n",
    "\n",
    "    def mrt_preproc_inputs(\n",
    "        self, rpe_options, pe_dir, eddy_options, nthreads, out_file=\"preproc.nii.gz\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Set inputs to mrtrix3's dwipreproc.\n",
    "        Arguments:\n",
    "            out_file: name of output file\n",
    "            rpe_options (str): specify phase encoding design -rpe_+ 'none/pair/all/header'\n",
    "            pe_dir (str): phase encoding direction(i,j,k)/(0,1,2)/(RL,PA,IS)\n",
    "            eddy_options (str): '\"--slm=linear \"' aditional commandline options to eddy command, with at least 1  space\n",
    "        \"\"\"\n",
    "        self.mrt_preproc.inputs.out_file = out_file\n",
    "        self.mrt_preproc.inputs.rpe_options = rpe_options  # -rpe_none\n",
    "        self.mrt_preproc.inputs.pe_dir = pe_dir\n",
    "        self.mrt_preproc.inputs.eddy_options = eddy_options\n",
    "        if nthreads is None:\n",
    "            pass\n",
    "        elif type(nthreads) == int:\n",
    "            self.mrt_preproc.inputs.nthreads = nthreads\n",
    "        else:\n",
    "            sys.exit(\"denoise nthreads input has to be an integer\")\n",
    "\n",
    "    def atlas_inputs(self, atlas_dir, atlas_names):\n",
    "        \"\"\"\n",
    "        Input where to load atlases for ROIs and co-registration\n",
    "        \"\"\"\n",
    "        self.atlas_dir = atlas_dir\n",
    "        self.atlas_names = atlas_names\n",
    "        atlas_template = {\"atlas\": atlas_dir + \"{file_name}\"}\n",
    "        self.atlas_source = Node(IdentityInterface(fields=[\"atlas_name\"]), name=\"atlas_source\")\n",
    "        self.atlas_source.iterables = [(\"atlas_name\"), self.atlas_names]\n",
    "        self.select_atlas = Node(SelectFiles(atlas_template), name=\"select_atlases\")\n",
    "        self.select_atlas.base_directory = self.atlas_dir\n",
    "\n",
    "    def b0extract_inputs(self, out_file=\"dwi_b0.nii.gz\", bzero=True):\n",
    "        self.b0extract.inputs.out_file = out_file\n",
    "        self.b0extract.inputs.bzero = bzero\n",
    "\n",
    "    def b0mean_inputs(self, out_file=\"dwi_b0_mean.nii.gz\", axis=3):\n",
    "        self.b0mean.inputs.operation = \"mean\"\n",
    "        self.b0mean.inputs.axis = axis\n",
    "        self.b0mean.inputs.out_file = out_file\n",
    "\n",
    "    def bet_inputs(\n",
    "        self, robust=True, mask=True, frac=0.25, out_file=\"dwi_brain.nii.gz\"\n",
    "    ):\n",
    "        if robust is True:\n",
    "            self.fsl_bet.inputs.robust = robust\n",
    "        else:\n",
    "            self.fsl_bet.inputs.reduce_bias = False\n",
    "\n",
    "        self.fsl_bet.inputs.mask = mask\n",
    "        self.fsl_bet.inputs.frac = 0.25\n",
    "        self.fsl_bet.inputs.out_file = out_file\n",
    "\n",
    "    def linear_coreg_inputs(\n",
    "        self,\n",
    "        dims=3,\n",
    "        prefix=\"atlas_in_dwi_affine\",\n",
    "        collapse=True,\n",
    "        transform=[\"Affine\"],\n",
    "        parameters=[(0.1,)],\n",
    "        metric=[\"MI\"],\n",
    "        weight=[1],\n",
    "        radius_bins=[64],\n",
    "        num_iter=[[500, 200, 200, 100]],\n",
    "        threshold=[1e-06],\n",
    "        window_size=[10],\n",
    "        sigmas=[[4, 2, 1, 0]],\n",
    "        units=[\"vox\"],\n",
    "        shrink=[[8, 4, 2, 1]],\n",
    "        histogram=True,\n",
    "        output=\"atlas_in_dwi_affine.nii.gz\",\n",
    "    ):\n",
    "        self.linear_coreg.inputs.dimension = dims\n",
    "        self.linear_coreg.inputs.output_transform_prefix = prefix\n",
    "        self.linear_coreg.inputs.collapse_output_transforms = collapse\n",
    "        self.linear_coreg.inputs.transforms = transform\n",
    "        self.linear_coreg.inputs.transform_parameters = parameters\n",
    "        self.linear_coreg.inputs.metric = metric\n",
    "        self.linear_coreg.inputs.metric_weight = weight  # default, value ignored by ANTS\n",
    "        self.linear_coreg.inputs.radius_or_number_of_bins = radius_bins\n",
    "        # -convergence\n",
    "        self.linear_coreg.inputs.number_of_iterations = num_iter\n",
    "        self.linear_coreg.inputs.convergence_threshold = threshold\n",
    "        self.linear_coreg.inputs.convergence_window_size = window_size\n",
    "        # -s\n",
    "        self.linear_coreg.inputs.smoothing_sigmas = sigmas\n",
    "        self.linear_coreg.inputs.sigma_units = units\n",
    "        # -f\n",
    "        self.linear_coreg.inputs.shrink_factors = shrink\n",
    "        self.linear_coreg.inputs.use_histogram_matching = histogram  # -u flag\n",
    "        self.linear_coreg.inputs.output_warped_image = output\n",
    "    \n",
    "    def nonlinear_coreg_inputs(\n",
    "        self,\n",
    "        dims=3,\n",
    "        prefix=\"atlas_in_dwi_syn\",\n",
    "        collapse=True,\n",
    "        transform=['SyN'],\n",
    "        parameters=[(0.1,)],\n",
    "        metric=[\"MI\"],\n",
    "        weight=[1],\n",
    "        radius_bins=[64],\n",
    "        num_iter=[[500, 200, 200, 100]],\n",
    "        threshold=[1e-06],\n",
    "        window_size=[10],\n",
    "        sigmas=[[4, 2, 1, 0]],\n",
    "        units=[\"vox\"],\n",
    "        shrink=[[8, 4, 2, 1]],\n",
    "        histogram=True,\n",
    "        output=\"atlas_in_dwi_syn.nii.gz\",\n",
    "    ):\n",
    "        self.nonlinear_coreg.inputs.dimension = dims\n",
    "        self.nonlinear_coreg.inputs.output_transform_prefix = prefix\n",
    "        self.nonlinear_coreg.inputs.collapse_output_transforms = collapse\n",
    "        self.nonlinear_coreg.inputs.transforms = transform\n",
    "        self.nonlinear_coreg.inputs.transform_parameters = parameters\n",
    "        self.nonlinear_coreg.inputs.metric = metric\n",
    "        self.nonlinear_coreg.inputs.metric_weight = weight  # default, value ignored by ANTS\n",
    "        self.nonlinear_coreg.inputs.radius_or_number_of_bins = radius_bins\n",
    "        # -convergence\n",
    "        self.nonlinear_coreg.inputs.number_of_iterations = num_iter\n",
    "        self.nonlinear_coreg.inputs.convergence_threshold = threshold\n",
    "        self.nonlinear_coreg.inputs.convergence_window_size = window_size\n",
    "        # -s\n",
    "        self.nonlinear_coreg.inputs.smoothing_sigmas = sigmas\n",
    "        self.nonlinear_coreg.inputs.sigma_units = units\n",
    "        # -f\n",
    "        self.nonlinear_coreg.inputs.shrink_factors = shrink\n",
    "        self.nonlinear_coreg.inputs.use_histogram_matching = histogram  # -u flag\n",
    "        self.nonlinear_coreg.inputs.output_warped_image = output\n",
    "\n",
    "    def connect_nodes(self, wf_name=\"pipetography\"):\n",
    "        # a workflow that will be filled in:\n",
    "        self.workflow = Workflow(name=wf_name, base_dir=self.data_dir + \"/derivatives\",)\n",
    "        # folder -> select files\n",
    "        self.workflow.connect(\n",
    "            self.sub_source, \"subject_id\", self.select_files, \"subject_id\",\n",
    "        )\n",
    "        # select files -> obtain bvec/bval path as tuple\n",
    "        self.workflow.connect(\n",
    "            self.select_files, \"b_files\", self.bfiles_input, \"in_List\",\n",
    "        )\n",
    "        # selected dwi -> denoise\n",
    "        self.workflow.connect(\n",
    "            self.select_files, \"dwi\", self.denoise, \"in_file\",\n",
    "        )\n",
    "        # denoised output -> datasink\n",
    "        self.workflow.connect(\n",
    "            self.denoise, \"out_file\", self.datasink, \"preproc.@denoised\",\n",
    "        )\n",
    "        # denoised output -> ringing removal\n",
    "        self.workflow.connect(\n",
    "            self.denoise, \"out_file\", self.ringing, \"in_file\",\n",
    "        )\n",
    "        # ringing removal -> datasink\n",
    "        self.workflow.connect(\n",
    "            self.ringing, \"out_file\", self.datasink, \"preproc.@ringing_removed\",\n",
    "        )\n",
    "        # ringing removal -> bias field correction\n",
    "        self.workflow.connect(\n",
    "            self.ringing, \"out_file\", self.ants_bfc, \"in_file\",\n",
    "        )\n",
    "        # bias field corrected -> datasink\n",
    "        self.workflow.connect(\n",
    "            self.ants_bfc, \"out_file\", self.datasink, \"preproc.@biasCorrected\",\n",
    "        )\n",
    "        # bias field corrected -> eddy correction\n",
    "        self.workflow.connect(\n",
    "            self.ants_bfc, \"out_file\", self.mrt_preproc, \"in_file\",\n",
    "        )\n",
    "        # grad_fsl for eddy correction:\n",
    "        self.workflow.connect(\n",
    "            self.bfiles_input, \"out_path\", self.mrt_preproc, \"grad_fsl\",\n",
    "        )\n",
    "        # preproc --> data sink\n",
    "        self.workflow.connect(\n",
    "            self.mrt_preproc, \"out_file\", self.datasink, \"preproc.@preproced\",\n",
    "        )\n",
    "        # b0 extractions:\n",
    "        self.workflow.connect(\n",
    "            self.mrt_preproc, \"out_file\", self.b0extract, \"in_file\",\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.bfiles_input, \"out_path\", self.b0extract, \"grad_fsl\",\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.b0extract, \"out_file\", self.b0mean, \"in_file\",\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.b0mean, \"out_file\", self.fsl_bet, \"in_file\",\n",
    "        )\n",
    "        # extractions --> datasink:\n",
    "        self.workflow.connect(\n",
    "            self.b0extract, \"out_file\", self.datasink, \"extraction.@volume\",\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.b0mean, \"out_file\", self.datasink, \"extraction.@mean\",\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.fsl_bet, \"mask_file\", self.datasink, \"extraction.@BET_mask\",\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.fsl_bet, \"out_file\", self.datasink, \"extraction.@BET_image\",\n",
    "        )\n",
    "        # coregistration of atlases to DWI, select atlases as moving image\n",
    "        self.workflow.connect(\n",
    "            self.atlas_source, 'atlas_name', self.select_atlas, 'file_name'\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.select_atlas, 'atlas', self.linear_coreg, 'moving_image'\n",
    "        )\n",
    "        # use extracted brain as target brain for co-registration, no dwi noise\n",
    "        self.workflow.connect(\n",
    "            self.fsl_bet, 'out_file', self.linear_coreg, 'fixed_image'\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.fsl_bet, 'out_file', self.nonlinear_coreg, 'fixed_image'\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.linear_coreg, 'warped_image', self.nonlinear_coreg, 'moving_image'\n",
    "        )\n",
    "        # coreg --> datasink\n",
    "        self.workflow.connect(\n",
    "            self.linear_coreg, 'warped_image', self.datasink, 'coreg.@affine_atlas'\n",
    "        )\n",
    "        self.workflow.connect(\n",
    "            self.nonlinear_coreg, 'warped_image', self.datasink, 'coreg.@syn_atlas'\n",
    "        )\n",
    "        #\n",
    "        \n",
    "    def default_setup(self, phase_encoding_design = \"-rpe_none\", phase_encoding_dir = \"j-\"):\n",
    "        \"\"\"\n",
    "        Set up pipeline parameters with all default settings blindly\n",
    "        You want to use this for a quick test run. Then tweak parameters after examining all output images\n",
    "        Note that this assumes input options for eddy current correction as \"--slm=linear\" \n",
    "        Arguments:\n",
    "            phase_encoding_design (str): defaults to \"-rpe_none\", or no reverse phase encoding volume, eddy current and motion correction only, other options include \"rpe_pair, rpe_all, rpe_header\"\n",
    "            phase_encoding_dir (str): defaults to \"j-\", or anterior to posterior. (Options: i,j,k or RL, PA, IS)\n",
    "        \"\"\"\n",
    "        self.denoise_inputs(force = True, quiet = True)\n",
    "        self.DeGibbs_inputs()\n",
    "        self.ants_bfc_inputs()\n",
    "        self.mrt_preproc_inputs(\n",
    "            rpe_options=phase_encoding_design,\n",
    "            pe_dir=phase_encoding_dir,\n",
    "            eddy_options='\"--slm=linear --verbose\"',\n",
    "            nthreads=4,\n",
    "            )\n",
    "        self.b0extract_inputs()\n",
    "        self.b0mean_inputs()\n",
    "        self.bet_inputs()\n",
    "        self.atlas_inputs(atlas_dir=str(input('Please indicate directory with atlas volumes: ')), atlas_names=list(input('Please indicate list of selected atlas names: ')))\n",
    "        self.linear_coreg_inputs() #defaults\n",
    "        self.nonlinear_coreg_inputs() #defaults\n",
    "        self.connect_nodes(wf_name = 'default_workflow')\n",
    "        return print(self.__dict__)\n",
    "        \n",
    "    def draw_pipeline(self):\n",
    "        self.workflow.write_graph(graph2use='orig', dotfilename = 'pipetography.dot')\n",
    "        \n",
    "    def run_pipeline(self, parallel = True):\n",
    "        if parallel is True:\n",
    "            processes = int(input('Number of Processes: '))\n",
    "            self.workflow.run('MultiProc', plugin_args = {'n_procs': processes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating layout of data directory, might take a while if there are a lot of subjects\n"
     ]
    }
   ],
   "source": [
    "#create pipeline:\n",
    "preproc_dwi = pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if our environment is properly set-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FSLOUTPUTTYPE is valid\n",
      "FSLDIR is valid\n",
      "ANTS is valid\n",
      "mrtrix3 is valid\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "preproc_dwi.check_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please indicate an output directory:  'output'\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "#set output destination:\n",
    "preproc_dwi.set_datasink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at what's in the `pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_dir': 'data',\n",
       " 'sub_list': ['11048'],\n",
       " 'layout': BIDS Layout: ...ers/xxie/lab/pipetography/data | Subjects: 1 | Sessions: 1 | Runs: 0,\n",
       " 'dwi_file': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz',\n",
       " 'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*',\n",
       " 'sub_template': {'dwi': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz',\n",
       "  'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*'},\n",
       " 'sub_source': data_source,\n",
       " 'select_files': select_files,\n",
       " 'bfiles_input': select_bfiles,\n",
       " 'denoise': denoise,\n",
       " 'ringing': ringing_removal,\n",
       " 'ants_bfc': ants_bias_correct,\n",
       " 'mrt_preproc': mrtrix3_preproc,\n",
       " 'atlas_dir': None,\n",
       " 'atlas_names': None,\n",
       " 'atlas_source': None,\n",
       " 'select_atlas': None,\n",
       " 'b0extract': dwiextract,\n",
       " 'b0mean': mrmath,\n",
       " 'fsl_bet': brain_extraction,\n",
       " 'linear_coreg': linear_registration,\n",
       " 'nonlinear_coreg': nonlinear_registration,\n",
       " 'datasink': datasink,\n",
       " 'workflow': None}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_dwi.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set up preprocessing pipeline with default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please indicate directory with atlas volumes:  '/Users/xxie/lab/atlases'\n",
      "Please indicate list of selected atlas names:  ['BN_Atlas_246_2mm.nii','DK_atlas86_1mm.nii']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dir': 'data', 'sub_list': ['11048'], 'layout': BIDS Layout: ...ers/xxie/lab/pipetography/data | Subjects: 1 | Sessions: 1 | Runs: 0, 'dwi_file': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz', 'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*', 'sub_template': {'dwi': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz', 'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*'}, 'sub_source': default_workflow.data_source, 'select_files': default_workflow.select_files, 'bfiles_input': default_workflow.select_bfiles, 'denoise': default_workflow.denoise, 'ringing': default_workflow.ringing_removal, 'ants_bfc': default_workflow.ants_bias_correct, 'mrt_preproc': default_workflow.mrtrix3_preproc, 'atlas_dir': \"'/Users/xxie/lab/atlases'\", 'atlas_names': ['[', \"'\", 'B', 'N', '_', 'A', 't', 'l', 'a', 's', '_', '2', '4', '6', '_', '2', 'm', 'm', '.', 'n', 'i', 'i', \"'\", ',', \"'\", 'D', 'K', '_', 'a', 't', 'l', 'a', 's', '8', '6', '_', '1', 'm', 'm', '.', 'n', 'i', 'i', \"'\", ']'], 'atlas_source': default_workflow.atlas_source, 'select_atlas': default_workflow.select_atlases, 'b0extract': default_workflow.dwiextract, 'b0mean': default_workflow.mrmath, 'fsl_bet': default_workflow.brain_extraction, 'linear_coreg': default_workflow.linear_registration, 'nonlinear_coreg': default_workflow.nonlinear_registration, 'datasink': default_workflow.datasink, 'workflow': default_workflow}\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "#usage\n",
    "preproc_dwi.default_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR we can fill this in one by one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's tell the pipeline where we have atlas volumes and which ones to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "preproc_dwi.atlas_inputs(atlas_dir = '/Users/xxie/lab/atlases', atlas_names = ['BN_Atlas_246_2mm.nii','DK_atlas86_1mm.nii'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we give inputs to the `denoise` Node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "preproc_dwi.denoise_inputs(force = True, quiet = True)\n",
    "# we kept everything else default, like output names and number of threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gibbs ringing removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "preproc_dwi.DeGibbs_inputs() # keep it default\n",
    "print('Output file name is ' + preproc_dwi.ringing.inputs.out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANTs Bias Field Correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "preproc_dwi.ants_bfc_inputs() # keep it default:\n",
    "preproc_dwi.ants_bfc.inputs.print_traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`in_file` is undefined because we will feed it this information once we connect our individual functions.\n",
    "\n",
    "Next let's set up eddy current/motion correction, we need to tell the pipeline the phase encoding settings and inputs to eddy algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "preproc_dwi.mrt_preproc_inputs(\n",
    "    rpe_options=\"-rpe_none\",\n",
    "    pe_dir=\"j-\",\n",
    "    eddy_options='\"--slm=linear --verbose\"',\n",
    "    nthreads=4,\n",
    ")\n",
    "preproc_dwi.mrt_preproc.inputs.print_traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grad_fsl` and `in_file` will be input via connected workflow later\n",
    "\n",
    "Next, we set-up brain extraction from B0 volumes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "# Extract b0 volumes:\n",
    "preproc_dwi.b0extract_inputs() #default\n",
    "# Create average B0 volume:\n",
    "preproc_dwi.b0mean_inputs() #default\n",
    "# Extract brain from B0 average volume:\n",
    "preproc_dwi.bet_inputs() #defaults again, using FSL's BET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANTs registration set up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "preproc_dwi.linear_coreg_inputs() #defaults\n",
    "preproc_dwi.nonlinear_coreg_inputs() #defaults\n",
    "preproc_dwi.nonlinear_coreg.inputs.print_traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the default settings may not be optimal for your dataset, run the processing for a test image and see the intermediate results and then tweak the available inputs to improve the output image quality.\n",
    "\n",
    "Now that our pre-processing Nodes are properly setup, we can connect and create a workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "preproc_dwi.connect_nodes(wf_name = 'pipetography_workflow')\n",
    "preproc_dwi.draw_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the final workflow we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "from IPython.display import Image\n",
    "Image('data/derivatives/test_run/pipetography_detailed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracts",
   "language": "python",
   "name": "tracts"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
