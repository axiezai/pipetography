{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module Postprocessing\n",
    "---\n",
    "\n",
    "Nipype interfaces for generating connectomes after pre-processing of DWI and `.trk` generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "import os\n",
    "\n",
    "from nipype import IdentityInterface\n",
    "from nipype.pipeline import Node, Workflow\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.interfaces.base import CommandLine, CommandLineInputSpec, File, TraitedSpec, traits\n",
    "from nipype.interfaces.mrtrix3.connectivity import LabelConvert\n",
    "from nipype.interfaces.mrtrix3.utils import Generate5tt\n",
    "from nipype.interfaces.mrtrix3.preprocess import ResponseSD\n",
    "from nipype.interfaces.mrtrix3.reconst import EstimateFOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atlas files input:\n",
    "\n",
    "Use `IdentityInterface` as a node for atlas inputs. Atlas inputs as a list if constructing multiple connnectomes. Look-up tables should also be an input. \n",
    "\n",
    "https://miykael.github.io/nipype_tutorial/notebooks/basic_data_input.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201001-10:14:41,949 nipype.workflow INFO:\n",
      "\t Workflow choose_atlas settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "201001-10:14:41,960 nipype.workflow INFO:\n",
      "\t Running serially.\n",
      "201001-10:14:41,961 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"choose_atlas.select_atlas\" in \"/private/var/folders/26/ys2mhp6j58n047rd6tvx76sm0000gp/T/tmpwdjftgxd/choose_atlas/_atlas_name_desikan-killiany/select_atlas\".\n",
      "201001-10:14:41,966 nipype.workflow INFO:\n",
      "\t [Node] Running \"select_atlas\" (\"nipype.interfaces.io.SelectFiles\")\n",
      "201001-10:14:41,972 nipype.workflow INFO:\n",
      "\t [Node] Finished \"choose_atlas.select_atlas\".\n",
      "201001-10:14:41,973 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"choose_atlas.datasink\" in \"/private/var/folders/26/ys2mhp6j58n047rd6tvx76sm0000gp/T/tmp_gqjektk/choose_atlas/_atlas_name_desikan-killiany/datasink\".\n",
      "201001-10:14:41,980 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasink\" (\"nipype.interfaces.io.DataSink\")\n",
      "201001-10:14:41,989 nipype.workflow INFO:\n",
      "\t [Node] Finished \"choose_atlas.datasink\".\n",
      "201001-10:14:41,990 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"choose_atlas.select_atlas\" in \"/private/var/folders/26/ys2mhp6j58n047rd6tvx76sm0000gp/T/tmppo4ajwax/choose_atlas/_atlas_name_brainnectome/select_atlas\".\n",
      "201001-10:14:41,996 nipype.workflow INFO:\n",
      "\t [Node] Running \"select_atlas\" (\"nipype.interfaces.io.SelectFiles\")\n",
      "201001-10:14:42,2 nipype.workflow INFO:\n",
      "\t [Node] Finished \"choose_atlas.select_atlas\".\n",
      "201001-10:14:42,3 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"choose_atlas.datasink\" in \"/private/var/folders/26/ys2mhp6j58n047rd6tvx76sm0000gp/T/tmpyg81ry_z/choose_atlas/_atlas_name_brainnectome/datasink\".\n",
      "201001-10:14:42,10 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasink\" (\"nipype.interfaces.io.DataSink\")\n",
      "201001-10:14:42,16 nipype.workflow INFO:\n",
      "\t [Node] Finished \"choose_atlas.datasink\".\n",
      "total 936\n",
      "-r--r--r--@ 3 xxie  staff   172K Sep 30 16:09 BN_Atlas_246_1mm.nii.gz\n",
      "-r--r--r--  3 xxie  staff   292K Sep 30 19:35 DK_Atlas_86_1mm.nii.gz\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "#usage\n",
    "\n",
    "atlas_dir = '/Users/xxie/lab/Human_Brain_Atlases'  # needs to be defined... either as an user input or pre-defined BIDS dir\n",
    "atlas_list = ['brainnectome', 'desikan-killiany']  # probably an input as well, currently have LUT corrected images for desikan-killiany, brainnectome, aal\n",
    "\n",
    "# Node for IdentityInterface\n",
    "atlas_source = Node(IdentityInterface(fields = ['atlas_name']), \n",
    "                    name = 'atlas_source')\n",
    "atlas_source.iterables = [('atlas_name', atlas_list)]  # iterate over atlas input names\n",
    "\n",
    "# Node for select files: actually selecting files\n",
    "atlas_template = {\n",
    "    'atlases': os.path.join(\n",
    "        atlas_dir, '{atlas_name}', '*_1mm.nii.gz' \n",
    "    )\n",
    "}\n",
    "atlas_file = Node(\n",
    "    SelectFiles(atlas_template),\n",
    "    base_directory=atlas_dir,\n",
    "    name='select_atlas'\n",
    ")\n",
    "\n",
    "# Create datasink for selected files\n",
    "datasink = Node(DataSink(base_directory = '/Users/xxie/lab/pipetography/outputs',\n",
    "               container='datasink'),\n",
    "                name='datasink')\n",
    "\n",
    "wf_atlas = Workflow(name=\"choose_atlas\")\n",
    "wf_atlas.connect(atlas_source, 'atlas_name', atlas_file, 'atlas_name')\n",
    "wf_atlas.connect(atlas_file, 'atlases', datasink, 'atlases')\n",
    "wf_atlas.run()\n",
    "\n",
    "! ls -lh /Users/xxie/lab/pipetography/outputs/datasink/atlases/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject files input:\n",
    "\n",
    "Tracts `.tck` files input (need to convert from trk to tck if using NVIDIA cuda, currently included in shell script attached to NVIDIA singularity).\n",
    "\n",
    "Whole brain volume `T1.mgz` files input, these are outputs of freesurfer's `recon-all`, subsequently used to generate tissue segmented files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201001-11:20:16,355 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"subj_source\" in \"/private/var/folders/26/ys2mhp6j58n047rd6tvx76sm0000gp/T/tmpd8y9s0wa/subj_source\".\n",
      "201001-11:20:16,360 nipype.workflow INFO:\n",
      "\t [Node] Running \"subj_source\" (\"nipype.interfaces.utility.base.IdentityInterface\")\n",
      "201001-11:20:16,365 nipype.workflow INFO:\n",
      "\t [Node] Finished \"subj_source\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "session_id = 002\n",
       "subject_id = 01"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/Users/xxie/sample_data/dwipreproc'\n",
    "session_id = '002'\n",
    "subject_id = '01'\n",
    "\n",
    "subj_source = Node(IdentityInterface(fields=[\"subject_id\", \"session_id\"]), name = 'subj_source')\n",
    "subj_template = {\n",
    "    'tck': os.path.join(data_dir, 'cuda_tracking', '_session_id_{session_id}_subject_id_{subject_id}', 'sub-{subject_id}_ses-{session_id}.tck'),\n",
    "    'dwi': os.path.join(data_dir, 'derivatives', 'dwi_acpc_aligned_1mm', '_session_id_{session_id}_subject_id_{subject_id}', 'dwi_acpc_1mm.mif'),\n",
    "    'acpcT1':  os.path.join(data_dir, 'derivatives', 't1_acpc_aligned', '_session_id_{session_id}_subject_id_{subject_id}', 'acpc_t1.nii')\n",
    "}\n",
    "subj_source.inputs.subject_id = subject_id\n",
    "subj_source.inputs.session_id = session_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTS Registration\n",
    "\n",
    "Align atlases to DWI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "#usage\n",
    "\n",
    "linear_reg = Node(ants.Registration(), name = 'linear_Registration')\n",
    "# Registration inputs:\n",
    "#linear_reg.inputs.moving_image = atlas_dir #need DIR to atlas\n",
    "linear_reg.inputs.output_transform_prefix = 'atlas_in_dwi_affine'\n",
    "linear_reg.inputs.dimension = 3 #-d\n",
    "# -tranform\n",
    "linear_reg.inputs.collapse_output_transforms = True # -z flag\n",
    "linear_reg.inputs.transforms = ['Affine']\n",
    "linear_reg.inputs.transform_parameters=[(0.1,)]\n",
    "# -metric\n",
    "linear_reg.inputs.metric = ['MI']\n",
    "linear_reg.inputs.metric_weight = [1] #default, value ignored by ANTS\n",
    "linear_reg.inputs.radius_or_number_of_bins = [64]\n",
    "# -convergence\n",
    "linear_reg.inputs.number_of_iterations = [[500,200,200,100]]\n",
    "linear_reg.inputs.convergence_threshold = [1e-06]\n",
    "linear_reg.inputs.convergence_window_size = [10]\n",
    "# -s\n",
    "linear_reg.inputs.smoothing_sigmas = [[4,2,1,0]]\n",
    "linear_reg.inputs.sigma_units = ['vox']\n",
    "# -f\n",
    "linear_reg.inputs.shrink_factors = [[8,4,2,1]]\n",
    "linear_reg.inputs.use_histogram_matching = [True] # -u flag\n",
    "linear_reg.inputs.output_warped_image = 'atlas_in_dwi_affine.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "#usage\n",
    "\n",
    "#### additional nonlinear registration node:\n",
    "syn_reg = Node(ants.Registration(), name = 'nonlinear_registration')\n",
    "# Registration inputs:\n",
    "#syn_reg.inputs.moving_image = 'interface_testing/atlas_in_dwi_affine.nii.gz' #need DIR to atlas\n",
    "syn_reg.inputs.output_transform_prefix = 'atlas_in_dwi_syn'\n",
    "syn_reg.inputs.dimension = 3 #-d\n",
    "# -tranform\n",
    "syn_reg.inputs.collapse_output_transforms = True # -z flag\n",
    "syn_reg.inputs.transforms = ['SyN']\n",
    "syn_reg.inputs.transform_parameters=[(0.1,)]\n",
    "# -metric\n",
    "syn_reg.inputs.metric = ['MI']\n",
    "syn_reg.inputs.metric_weight = [1] #default, value ignored by ANTS\n",
    "syn_reg.inputs.radius_or_number_of_bins = [64]\n",
    "# -convergence\n",
    "syn_reg.inputs.number_of_iterations = [[500,200,200,100]]\n",
    "syn_reg.inputs.convergence_threshold = [1e-06]\n",
    "syn_reg.inputs.convergence_window_size = [10]\n",
    "# -s\n",
    "syn_reg.inputs.smoothing_sigmas = [[4,2,1,0]]\n",
    "syn_reg.inputs.sigma_units = ['vox']\n",
    "# -f\n",
    "syn_reg.inputs.shrink_factors = [[8,4,2,1]]\n",
    "syn_reg.inputs.use_histogram_matching = [True] # -u flag\n",
    "syn_reg.inputs.output_warped_image = 'atlas_in_dwi_syn.nii.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOD Modeling\n",
    "\n",
    "Create white matter fiber orientation image. First use `dwi2response dhollander` to generate white matter, grey matter, and CSF spherical deconvolution response files, then use `dwi2fod msmt_csd` with a tissue response function input to generate FODs for the white matter, gray matter, and CSF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dwi2response\n",
    "#dwi2fod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mrtrix3 - SIFT2\n",
    "\n",
    "Spherical-deconvolution Informed Filtering of Tractograms (SIFT) `tcksift2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class tckSIFT2InputSpec(CommandLineInputSpec):\n",
    "    in_file = File(\n",
    "        exists=True,\n",
    "        mandatory=True,\n",
    "        argstr=\"%s\",\n",
    "        position=-2,\n",
    "        desc=\"input track file\"\n",
    "    )\n",
    "    in_fod = File(\n",
    "        exists=True,\n",
    "        mandatory=True,\n",
    "        argstr=\"%s\",\n",
    "        position=-1,\n",
    "        desc=\"input image containing the spherical harmonics of the fiber orientation distributions\"\n",
    "    )\n",
    "    proc_mask = File(\n",
    "        exists=True,\n",
    "        argstr=\"-proc_mask %s\",\n",
    "        desc=\"provide an image containing the processing mask weights for the model; image spatial dimensions must match the fixel image\"\n",
    "    )\n",
    "    act = File(\n",
    "        exists=True,\n",
    "        argstr=\"-act %s\",\n",
    "        desc=\"use an ACT five-tissue-type segmented anatomical image to derive the processing mask\"\n",
    "    )\n",
    "    fd_scale_gm = traits.Bool(\n",
    "        argstr=\"-fd_scale_gm\",\n",
    "        desc=\"in conjunction with -act to heuristically downsize the fibre density estimates based on the presence of GM in the voxel. This can assist in reducing tissue interface effects when using a single-tissue deconvolution algorithm\"\n",
    "    )\n",
    "    nthreads = traits.Int(\n",
    "        argstr=\"-nthreads %d\",\n",
    "        desc=\"number of threads. if zero, the number\" \" of available cpus will be used\",\n",
    "        nohash=True,\n",
    "    )\n",
    "    \n",
    "class tckSIFT2OutputSpec(TraitedSpec):\n",
    "    out_file=File(argstr=\"%s\", desc=\"output text file containing the weighting factor for each streamline\")\n",
    "    \n",
    "class tckSIFT2(CommandLine):\n",
    "    \"\"\"\n",
    "    Interface with mrtrix3 package\n",
    "    Spherical-deconvolution informed filtering of tractograms - sift2\n",
    "    Optimise per-streamline cross-section multipliers to match a whole-brain tractogram to fixel-wise fibre densities\n",
    "    \"\"\"\n",
    "    _cmd=\"tcksift2\"\n",
    "    input_spec=tckSIFT2InputSpec\n",
    "    output_spec=tckSIFT2OutputSpec\n",
    "    \n",
    "    def _list_outputs(self):\n",
    "        outputs=self.output_spec().get()\n",
    "        outputs[\"out_file\"] = os.path.abspath(self.inputs.out_file)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tissue type specific masks\n",
    "\n",
    "Use `fsl` algorithm to generate tissue specific `.mif` file with `5ttgen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "#usage\n",
    "gen5tt = Generate5tt()\n",
    "gen5tt.inputs.in_file = ''  # T1 acpc aligned nifti\n",
    "gen5tt.inputs.algorithm = 'fsl'  # fsl or freesurfer, fsl is preferred in my opinion\n",
    "gen5tt.inputs.out_file = '5tt.mif'\n",
    "# gen5tt.inputs.args = '-premasked'  # indicating a brain mask has already been applied to input image\n",
    "gen5tt.cmdline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweak Atlas labels with look up tables.\n",
    "\n",
    "mrtrix3's `labelconvert` and `labelsgmfix` if using freesurfer atlas.\n",
    "\n",
    "Use the nipype interface for `LabelConvert`, and declare a mrtrix3 path to its `/share/mrtrix3/labelconvert/` folder where the target connectome lookup tabel for output images reside. Available files include: \n",
    "\n",
    "    - aal.txt\n",
    "    - aal2.txt\n",
    "    - fs_default.txt\n",
    "    - hcpmmp1_ordered.txt\n",
    "    - hcpmmp1_original.txt\n",
    "    - lpba40.txt\n",
    "    - fs2lobes_cinginc_convert.txt\n",
    "    - fs2lobes_cinginc_labels.txt\n",
    "    - fs2lobes_cingsep_convert.txt\n",
    "    - fs2lobes_cingsep_labels.txt\n",
    "    \n",
    "Please refer to https://mrtrix.readthedocs.io/en/latest/quantitative_structural_connectivity/labelconvert_tutorial.html#labelconvert-tutorial for detailed explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrt_labels = LabelConvert()\n",
    "mrt_labels.inputs.in_file = '/Users/xxie/lab/atlases/BN_Atlas_246_2mm.nii'\n",
    "mrt_labels.inputs.in_lut = '/Users/xxie/lab/atlases/BN_Atlas_246_LUT.txt'\n",
    "mrt_labels.inputs.cmdline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tck2connectome` for connectivity matrix and distance adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class MakeConnectomeInputSpec(CommandLineInputSpec):\n",
    "    \"\"\"\n",
    "    Specifying inputs to mrtrix3's tck2connectome\n",
    "    \"\"\"\n",
    "    in_file = File(\n",
    "        exists=True, mandatory=True, argstr=\"%s\", position=-3, desc=\"input tck file\"\n",
    "    )\n",
    "    in_parc = File(\n",
    "        exists=True, argstr=\"%s\", position=-2, desc=\"parcellation file\"\n",
    "    )\n",
    "    out_file = File(\n",
    "        argstr=\"%s\",\n",
    "        mandatory=True,\n",
    "        position=-1,\n",
    "        desc=\"output file connectivity csv file\",\n",
    "    )\n",
    "    nthreads = traits.Int(\n",
    "        argstr=\"-nthreads %d\",\n",
    "        desc=\"number of threads. if zero, the number\" \" of available cpus will be used\",\n",
    "        nohash=True,\n",
    "    )\n",
    "    in_weights = File(\n",
    "        exists=True,\n",
    "        argstr=\"-tck_weights_in %s\",\n",
    "        desc=\"specify a text scalar file containing the streamline weights\",\n",
    "    )\n",
    "    scale_length=traits.Bool(\n",
    "        argstr=\"-scale_length\",\n",
    "        desc=\"scale each contribution to the connectome edge by the length of the streamline\"\n",
    "    )\n",
    "    stat_edge=traits.Enum(\n",
    "        \"sum\",\n",
    "        \"mean\",\n",
    "        \"min\",\n",
    "        \"max\",\n",
    "        argstr=\"-stat_edge %s\",\n",
    "        desc=\"statistic for combining the values from all streamlines in an edge into a single scale value for that edge (options are: sum,mean,min,max;default=sum)\"\n",
    "    )\n",
    "    \n",
    "class MakeConnectomeOutputSpec(TraitedSpec):\n",
    "    out_file = File(argstr=\"%s\", desc=\"output connectome csv file\")\n",
    "    \n",
    "class MakeConnectome(CommandLine):\n",
    "    \"\"\"\n",
    "    mrtrix3's tck2connectome interface\n",
    "    \"\"\"\n",
    "    _cmd=\"tck2connectome\"\n",
    "    input_spec = MakeConnectomeInputSpec\n",
    "    output_spec = MakeConnectomeOutputSpec\n",
    "    \n",
    "    def _list_outputs(self):\n",
    "        outputs=self.output_spec().get()\n",
    "        outputs[\"out_file\"] = os.path.abspath(self.inputs.out_file)\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracts",
   "language": "python",
   "name": "tracts"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
