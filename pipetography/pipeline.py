# AUTOGENERATED! DO NOT EDIT! File to edit: 01_pipeline.ipynb (unless otherwise specified).

__all__ = ['pipeline']

# Cell
#export
import os, sys
from shutil import which

import pipetography.core as ppt

from nipype import IdentityInterface, Function
from nipype.interfaces.io import SelectFiles, DataSink
from nipype.pipeline import Node, MapNode, Workflow
from nipype.interfaces.mrtrix3.utils import BrainMask, DWIExtract, MRMath
from nipype.interfaces.mrtrix3.preprocess import MRDeGibbs
from nipype.interfaces import ants
from nipype.interfaces import fsl

# Cell
class pipeline:
    """
    A class containing functionalities and inputs to the image processing pipeline
    Input:
        BIDS_dir (str): Valid BIDS directory with DWI modality
    Attributes:
        data_dir (str)
        sub_list (List)
        layout (PyBIDS Layout)
        bfiles_fsl (tuple)
    """

    def __init__(self, BIDS_dir="data"):
        # variables
        self.data_dir = BIDS_dir
        self.sub_list, self.layout = ppt.get_subs(self.data_dir)
        self.dwi_file = os.path.join(
            "sub-{subject_id}", "ses-*", "dwi", "sub-{subject_id}_ses-*_dwi.nii.gz",
        )
        self.b_files = os.path.join(
            "sub-{subject_id}", "ses-1", "dwi", "sub-{subject_id}_ses-1_dwi.bv*"
        )
        self.sub_template = {"dwi": self.dwi_file, "b_files": self.b_files}
        # node for reading inputs
        self.sub_source = Node(IdentityInterface(fields=["subject_id"]), name="data_source")
        self.sub_source.iterables = [("subject_id", self.sub_list)]
        # node for selecting images and bfiles
        self.select_files = Node(
            SelectFiles(self.sub_template, base_directory=self.data_dir), name="select_files",
        )
        self.bfiles_input = Node(
            Function(
                input_names=["in_List"], output_names=["out_path"], function=ppt.get_bfiles_tuple,
            ),
            name="select_bfiles",
        )
        # preprocessing nodes:
        self.denoise = MapNode(ppt.dwidenoise(), name="denoise", iterfield="in_file")
        self.ringing = MapNode(MRDeGibbs(), name="ringing_removal", iterfield="in_file")
        self.ants_bfc = MapNode(
            ppt.N4BiasFieldCorrection(), name="ants_bias_correct", iterfield="in_file",
        )
        self.mrt_preproc = MapNode(ppt.dwipreproc(), name="mrtrix3_preproc", iterfield="in_file")
        # atlases:
        self.atlas_dir = None
        self.atlas_names = None
        self.atlas_source = None
        self.select_atlas = None
        # b0 volume brain and mask extraction:
        self.b0extract = MapNode(DWIExtract(), name="dwiextract", iterfield="in_file")
        self.b0mean = MapNode(MRMath(), name="mrmath", iterfield="in_file")
        self.fsl_bet = MapNode(fsl.BET(), name="brain_extraction", iterfield="in_file")
        # ants coregistration:
        self.linear_coreg = MapNode(
            ants.Registration(), name="linear_registration", iterfield="fixed_image",
        )
        self.nonlinear_coreg = MapNode(
            ants.Registration(), name="nonlinear_registration", iterfield="fixed_image",
        )
        # data sink:
        self.datasink = Node(DataSink(), name="datasink")
        # workflow for nipype
        self.workflow = None
        #

    def check_environment(self):
        """
        Check your computing environment for FSL environment variables `FSLOUTPUTTYPE` and `FSLDIR`
        Check if ANTs PATH is included in your environment
        Check if mrtrix3 is in your PATH
        """
        assert "FSLOUTPUTTYPE" in os.environ
        assert "FSLDIR" in os.environ
        if "FSLOUTPUTTYPE" in os.environ:
            print("FSLOUTPUTTYPE is valid")
        else:
            sys.exit("FSLOUTPUTTYPE is not defined, make sure FSL is configured!")

        if "FSLDIR" in os.environ:
            print("FSLDIR is valid")
        else:
            sys.exit("FSLOUTPUTTYPE is not defined, make sure FSL is configured!")

        #ANTS:
        assert "ANTSPATH" in os.environ
        print("ANTS is valid")
        #mrtrix:
        assert which('mrview') is not None
        print("mrtrix3 is valid")
        return None
        #

    def set_datasink(self):
        """
        Set directory where output files will be placed
        """
        output_dir = str(input('Please indicate an output directory: '))
        self.datasink.inputs.base_directory = output_dir

    def denoise_inputs(
        self,
        out_file="denoised.nii.gz",
        noise_file="noise_map.nii.gz",
        force=False,
        quiet=False,
        nthreads=None,
    ):
        """
        Set inputs to denoise node
        """
        self.denoise.inputs.out_file = out_file
        self.denoise.inputs.noise = noise_file
        if force is True:
            self.denoise.inputs.force = "-force"
        else:
            pass

        if quiet is True:
            self.denoise.inputs.quiet = "-quiet"
        else:
            pass

        if nthreads is None:
            pass
        elif type(nthreads) == int:
            self.denoise.inputs.nthreads = nthreads
        else:
            sys.exit("denoise nthreads input has to be an integer")

    def DeGibbs_inputs(self, out_file="ringing_removed.nii.gz"):
        """
        Set inputs to ringing removal node
        """
        self.ringing.inputs.out_file = out_file

    def ants_bfc_inputs(self, out_file="biasfieldcorrected.nii.gz", dims=4):
        """
        Set inputs to ANTs bias field correction node, currently incomplete
        """
        self.ants_bfc.inputs.out_file = out_file
        self.ants_bfc.inputs.dims = dims

    def mrt_preproc_inputs(
        self, rpe_options, pe_dir, eddy_options, nthreads, out_file="preproc.nii.gz",
    ):
        """
        Set inputs to mrtrix3's dwipreproc.
        Arguments:
            out_file: name of output file
            rpe_options (str): specify phase encoding design -rpe_+ 'none/pair/all/header'
            pe_dir (str): phase encoding direction(i,j,k)/(0,1,2)/(RL,PA,IS)
            eddy_options (str): '"--slm=linear "' aditional commandline options to eddy command, with at least 1  space
        """
        self.mrt_preproc.inputs.out_file = out_file
        self.mrt_preproc.inputs.rpe_options = rpe_options  # -rpe_none
        self.mrt_preproc.inputs.pe_dir = pe_dir
        self.mrt_preproc.inputs.eddy_options = eddy_options
        if nthreads is None:
            pass
        elif type(nthreads) == int:
            self.mrt_preproc.inputs.nthreads = nthreads
        else:
            sys.exit("denoise nthreads input has to be an integer")

    def atlas_inputs(self, atlas_dir, atlas_names):
        """
        Input where to load atlases for ROIs and co-registration
        """
        self.atlas_dir = atlas_dir
        self.atlas_names = atlas_names
        atlas_template = {"atlas": atlas_dir + "{file_name}"}
        self.atlas_source = Node(IdentityInterface(fields=["atlas_name"]), name="atlas_source")
        self.atlas_source.iterables = [("atlas_name"), self.atlas_names]
        self.select_atlas = Node(SelectFiles(atlas_template), name="select_atlases")
        self.select_atlas.base_directory = self.atlas_dir

    def b0extract_inputs(self, out_file="dwi_b0.nii.gz", bzero=True):
        self.b0extract.inputs.out_file = out_file
        self.b0extract.inputs.bzero = bzero

    def b0mean_inputs(self, out_file="dwi_b0_mean.nii.gz", axis=3):
        self.b0mean.inputs.operation = "mean"
        self.b0mean.inputs.axis = axis
        self.b0mean.inputs.out_file = out_file

    def bet_inputs(
        self, robust=True, mask=True, frac=0.25, out_file="dwi_brain.nii.gz"
    ):
        if robust is True:
            self.fsl_bet.inputs.robust = robust
        else:
            self.fsl_bet.inputs.reduce_bias = False

        self.fsl_bet.inputs.mask = mask
        self.fsl_bet.inputs.frac = 0.25
        self.fsl_bet.inputs.out_file = out_file

    def linear_coreg_inputs(
        self,
        dims=3,
        prefix="atlas_in_dwi_affine",
        collapse=True,
        transform=["Affine"],
        parameters=[(0.1,)],
        metric=["MI"],
        weight=[1],
        radius_bins=[64],
        num_iter=[[500, 200, 200, 100]],
        threshold=[1e-06],
        window_size=[10],
        sigmas=[[4, 2, 1, 0]],
        units=["vox"],
        shrink=[[8, 4, 2, 1]],
        histogram=True,
        output="atlas_in_dwi_affine.nii.gz",
    ):
        self.linear_coreg.inputs.dimension = dims
        self.linear_coreg.inputs.output_transform_prefix = prefix
        self.linear_coreg.inputs.collapse_output_transforms = collapse
        self.linear_coreg.inputs.transforms = transform
        self.linear_coreg.inputs.transform_parameters = parameters
        self.linear_coreg.inputs.metric = metric
        self.linear_coreg.inputs.metric_weight = weight  # default, value ignored by ANTS
        self.linear_coreg.inputs.radius_or_number_of_bins = radius_bins
        # -convergence
        self.linear_coreg.inputs.number_of_iterations = num_iter
        self.linear_coreg.inputs.convergence_threshold = threshold
        self.linear_coreg.inputs.convergence_window_size = window_size
        # -s
        self.linear_coreg.inputs.smoothing_sigmas = sigmas
        self.linear_coreg.inputs.sigma_units = units
        # -f
        self.linear_coreg.inputs.shrink_factors = shrink
        self.linear_coreg.inputs.use_histogram_matching = histogram  # -u flag
        self.linear_coreg.inputs.output_warped_image = output

    def nonlinear_coreg_inputs(
        self,
        dims=3,
        prefix="atlas_in_dwi_syn",
        collapse=True,
        transform=['SyN'],
        parameters=[(0.1,)],
        metric=["MI"],
        weight=[1],
        radius_bins=[64],
        num_iter=[[500, 200, 200, 100]],
        threshold=[1e-06],
        window_size=[10],
        sigmas=[[4, 2, 1, 0]],
        units=["vox"],
        shrink=[[8, 4, 2, 1]],
        histogram=True,
        output="atlas_in_dwi_syn.nii.gz",
    ):
        self.nonlinear_coreg.inputs.dimension = dims
        self.nonlinear_coreg.inputs.output_transform_prefix = prefix
        self.nonlinear_coreg.inputs.collapse_output_transforms = collapse
        self.nonlinear_coreg.inputs.transforms = transform
        self.nonlinear_coreg.inputs.transform_parameters = parameters
        self.nonlinear_coreg.inputs.metric = metric
        self.nonlinear_coreg.inputs.metric_weight = weight  # default, value ignored by ANTS
        self.nonlinear_coreg.inputs.radius_or_number_of_bins = radius_bins
        # -convergence
        self.nonlinear_coreg.inputs.number_of_iterations = num_iter
        self.nonlinear_coreg.inputs.convergence_threshold = threshold
        self.nonlinear_coreg.inputs.convergence_window_size = window_size
        # -s
        self.nonlinear_coreg.inputs.smoothing_sigmas = sigmas
        self.nonlinear_coreg.inputs.sigma_units = units
        # -f
        self.nonlinear_coreg.inputs.shrink_factors = shrink
        self.nonlinear_coreg.inputs.use_histogram_matching = histogram  # -u flag
        self.nonlinear_coreg.inputs.output_warped_image = output

    def connect_nodes(self, wf_name="pipetography"):
        # a workflow that will be filled in:
        self.workflow = Workflow(name=wf_name, base_dir=self.data_dir + "/derivatives",)
        # folder -> select files
        self.workflow.connect(
            self.sub_source, "subject_id", self.select_files, "subject_id",
        )
        # select files -> obtain bvec/bval path as tuple
        self.workflow.connect(
            self.select_files, "b_files", self.bfiles_input, "in_List",
        )
        # selected dwi -> denoise
        self.workflow.connect(
            self.select_files, "dwi", self.denoise, "in_file",
        )
        # denoised output -> datasink
        self.workflow.connect(
            self.denoise, "out_file", self.datasink, "preproc.@denoised",
        )
        # denoised output -> ringing removal
        self.workflow.connect(
            self.denoise, "out_file", self.ringing, "in_file",
        )
        # ringing removal -> datasink
        self.workflow.connect(
            self.ringing, "out_file", self.datasink, "preproc.@ringing_removed",
        )
        # ringing removal -> bias field correction
        self.workflow.connect(
            self.ringing, "out_file", self.ants_bfc, "in_file",
        )
        # bias field corrected -> datasink
        self.workflow.connect(
            self.ants_bfc, "out_file", self.datasink, "preproc.@biasCorrected",
        )
        # bias field corrected -> eddy correction
        self.workflow.connect(
            self.ants_bfc, "out_file", self.mrt_preproc, "in_file",
        )
        # grad_fsl for eddy correction:
        self.workflow.connect(
            self.bfiles_input, "out_path", self.mrt_preproc, "grad_fsl",
        )
        # preproc --> data sink
        self.workflow.connect(
            self.mrt_preproc, "out_file", self.datasink, "preproc.@preproced",
        )
        # b0 extractions:
        self.workflow.connect(
            self.mrt_preproc, "out_file", self.b0extract, "in_file",
        )
        self.workflow.connect(
            self.bfiles_input, "out_path", self.b0extract, "grad_fsl",
        )
        self.workflow.connect(
            self.b0extract, "out_file", self.b0mean, "in_file",
        )
        self.workflow.connect(
            self.b0mean, "out_file", self.fsl_bet, "in_file",
        )
        # extractions --> datasink:
        self.workflow.connect(
            self.b0extract, "out_file", self.datasink, "extraction.@volume",
        )
        self.workflow.connect(
            self.b0mean, "out_file", self.datasink, "extraction.@mean",
        )
        self.workflow.connect(
            self.fsl_bet, "mask_file", self.datasink, "extraction.@BET_mask",
        )
        self.workflow.connect(
            self.fsl_bet, "out_file", self.datasink, "extraction.@BET_image",
        )
        # coregistration of atlases to DWI, select atlases as moving image
        self.workflow.connect(
            self.atlas_source, 'atlas_name', self.select_atlas, 'file_name'
        )
        self.workflow.connect(
            self.select_atlas, 'atlas', self.linear_coreg, 'moving_image'
        )
        # use extracted brain as target brain for co-registration, no dwi noise
        self.workflow.connect(
            self.fsl_bet, 'out_file', self.linear_coreg, 'fixed_image'
        )
        self.workflow.connect(
            self.fsl_bet, 'out_file', self.nonlinear_coreg, 'fixed_image'
        )
        self.workflow.connect(
            self.linear_coreg, 'warped_image', self.nonlinear_coreg, 'moving_image'
        )
        # coreg --> datasink
        self.workflow.connect(
            self.linear_coreg, 'warped_image', self.datasink, 'coreg.@affine_atlas'
        )
        self.workflow.connect(
            self.nonlinear_coreg, 'warped_image', self.datasink, 'coreg.@syn_atlas'
        )
        #

    def default_setup(self, phase_encoding_design = "-rpe_none", phase_encoding_dir = "j-"):
        """
        Set up pipeline parameters with all default settings blindly
        You want to use this for a quick test run. Then tweak parameters after examining all output images
        Note that this assumes input options for eddy current correction as "--slm=linear"
        Arguments:
            phase_encoding_design (str): defaults to "-rpe_none", or no reverse phase encoding volume, eddy current and motion correction only, other options include "rpe_pair, rpe_all, rpe_header"
            phase_encoding_dir (str): defaults to "j-", or anterior to posterior. (Options: i,j,k or RL, PA, IS)
        """
        self.denoise_inputs(force = True, quiet = True)
        self.DeGibbs_inputs()
        self.ants_bfc_inputs()
        self.mrt_preproc_inputs(
            rpe_options=phase_encoding_design,
            pe_dir=phase_encoding_dir,
            eddy_options='"--slm=linear --verbose"',
            nthreads=4,
            )
        self.b0extract_inputs()
        self.b0mean_inputs()
        self.bet_inputs()
        self.atlas_inputs(atlas_dir=str(input('Please indicate directory with atlas volumes: ')), atlas_names=list(input('Please indicate list of selected atlas names: ')))
        self.linear_coreg_inputs() #defaults
        self.nonlinear_coreg_inputs() #defaults
        self.connect_nodes(wf_name = 'default_workflow')
        return print(self.__dict__)

    def draw_pipeline(self):
        self.workflow.write_graph(graph2use='orig', dotfilename = 'pipetography.dot')

    def run_pipeline(self, parallel = True):
        if parallel is True:
            processes = int(input('Number of Processes: '))
            self.workflow.run('MultiProc', plugin_args = {'n_procs': processes})